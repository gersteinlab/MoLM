{"cells": [{"cell_type": "markdown", "source": ["# MoleculeNet Task Using MolLM Embeddings + Random Forest Example"], "metadata": {"collapsed": false}, "id": "5207fbe93e5d927f"}, {"cell_type": "code", "outputs": [], "source": ["def load_bbbp(input_df):\n", "    smiles_list = input_df['smiles']\n", "    labels = input_df['p_np']\n", "    labels = labels.replace(0, -1)\n", "    return smiles_list, labels\n", "\n", "def load_tox21(input_df):\n", "    smiles_list = input_df['smiles']\n", "    tasks = ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD',\n", "       'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n", "    labels = input_df[tasks]\n", "    labels = labels.replace(0, -1)\n", "    labels = labels.fillna(0)\n", "    return smiles_list, labels\n", "\n", "def load_toxcast(input_df):\n", "    smiles_list = input_df['smiles']\n", "    tasks = list(input_df.columns)[1:]\n", "    labels = input_df[tasks]\n", "    labels = labels.replace(0, -1)\n", "    labels = labels.fillna(0)\n", "    return smiles_list, labels\n", "\n", "def load_sider(input_df):\n", "    smiles_list = input_df['smiles']\n", "    tasks = ['Hepatobiliary disorders',\n", "       'Metabolism and nutrition disorders', 'Product issues', 'Eye disorders',\n", "       'Investigations', 'Musculoskeletal and connective tissue disorders',\n", "       'Gastrointestinal disorders', 'Social circumstances',\n", "       'Immune system disorders', 'Reproductive system and breast disorders',\n", "       'Neoplasms benign, malignant and unspecified (incl cysts and polyps)',\n", "       'General disorders and administration site conditions',\n", "       'Endocrine disorders', 'Surgical and medical procedures',\n", "       'Vascular disorders', 'Blood and lymphatic system disorders',\n", "       'Skin and subcutaneous tissue disorders',\n", "       'Congenital, familial and genetic disorders',\n", "       'Infections and infestations',\n", "       'Respiratory, thoracic and mediastinal disorders',\n", "       'Psychiatric disorders', 'Renal and urinary disorders',\n", "       'Pregnancy, puerperium and perinatal conditions',\n", "       'Ear and labyrinth disorders', 'Cardiac disorders',\n", "       'Nervous system disorders',\n", "       'Injury, poisoning and procedural complications']\n", "    labels = input_df[tasks]\n", "    labels = labels.replace(0, -1)\n", "    return smiles_list, labels\n", "\n", "def load_clintox(input_df):\n", "    smiles_list = input_df['smiles']\n", "    tasks = ['FDA_APPROVED', 'CT_TOX']\n", "    labels = input_df[tasks]\n", "    labels = labels.replace(0, -1)\n", "    return smiles_list, labels\n", "\n", "def load_muv(input_df):\n", "    smiles_list = input_df['smiles']\n", "    tasks = ['MUV-466', 'MUV-548', 'MUV-600', 'MUV-644', 'MUV-652', 'MUV-689',\n", "       'MUV-692', 'MUV-712', 'MUV-713', 'MUV-733', 'MUV-737', 'MUV-810',\n", "       'MUV-832', 'MUV-846', 'MUV-852', 'MUV-858', 'MUV-859']\n", "    labels = input_df[tasks]\n", "    labels = labels.replace(0, -1)\n", "    labels = labels.fillna(0)\n", "    return smiles_list, labels\n", "\n", "def load_hiv(input_df):\n", "    smiles_list = input_df['smiles']\n", "    labels = input_df['HIV_active']\n", "    labels = labels.replace(0, -1)\n", "    return smiles_list, labels\n", "\n", "def load_bace(input_df):\n", "    smiles_list = input_df['mol']\n", "    labels = input_df['Class']\n", "    # convert 0 to -1\n", "    labels = labels.replace(0, -1)\n", "    return smiles_list, labels\n", "\n", "datasets = {\n", "    'bbbp': ('BBBP.csv', load_bbbp), #\n", "    'tox21': ('tox21.csv', load_tox21), #\n", "    'toxcast': ('toxcast_data.csv', load_toxcast), #\n", "    'sider': ('sider.csv', load_sider), #\n", "    'clintox': ('clintox.csv', load_clintox),\n", "    'muv': ('muv.csv', load_muv),\n", "    'hiv': ('HIV.csv', load_hiv), #sc\n", "    'bace': ('bace.csv', load_bace)\n", "}"], "metadata": {"collapsed": false, "ExecuteTime": {"end_time": "2024-03-15T19:33:29.868961Z", "start_time": "2024-03-15T19:33:29.844Z"}}, "id": "f8c83a6806cc1c2c", "execution_count": 1}, {"cell_type": "code", "outputs": [], "source": ["import importlib\n", "import sys\n", "\n", "import pandas as pd\n", "import torch\n", "from tqdm import tqdm\n", "\n", "dataset_base_path = '../../downstream/MoleculePrediction/dataset'"], "metadata": {"collapsed": false, "ExecuteTime": {"end_time": "2024-03-15T19:40:06.331159Z", "start_time": "2024-03-15T19:40:00.786426Z"}}, "id": "ebd9357b46eae550", "execution_count": 3}, {"cell_type": "code", "outputs": [], "source": ["sys.path.insert(0, '../../downstream/graph-transformer')\n", "MolLMPkg = importlib.import_module(\"MolLM\")\n", "MolLM = MolLMPkg.MolLM\n", "\n", "# Same checkpoint as property prediction\n", "model = MolLM('../../downstream/GraphTextRetrieval/all_checkpoints/model-epoch=394.ckpt', '../../downstream/GraphTextRetrieval/', '../../downstream/GraphTextRetrieval/bert_pretrained')\n", "model = model.to('cuda')\n", "\n", "for dataset, (dataset_csv, load_dataset_func) in datasets.items():\n", "    if dataset == 'bbbp' or dataset == 'tox21':\n", "        continue\n", "    print(dataset)\n", "    csv_path = f'{dataset_base_path}/{dataset}/raw/{dataset_csv}'\n", "    input_df = pd.read_csv(csv_path, sep=',')\n", "    smiles, labels = load_dataset_func(input_df)\n", "    embeddings = []\n", "    for i, smile in enumerate(tqdm(smiles)):\n", "        try:\n", "            embeddings.append(model.forward_molecule(smile))\n", "        except Exception as e:\n", "            print(f'Failed {dataset}-{i}: {e}')\n", "            embeddings.append(torch.zeros((1, 768)))\n", "    torch.save(embeddings, f'{dataset_base_path}/{dataset}/raw/molm.pt')\n", "    torch.save(labels, f'{dataset_base_path}/{dataset}/raw/molm_labels.pt')"], "metadata": {"collapsed": false}, "id": "98d9901c250cc949", "execution_count": null}, {"cell_type": "code", "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n", "[15:56:13] Explicit valence for atom # 1 N, 4, is greater than permitted\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] Explicit valence for atom # 6 N, 4, is greater than permitted\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] Explicit valence for atom # 6 N, 4, is greater than permitted\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] Explicit valence for atom # 11 N, 4, is greater than permitted\n", "[15:56:13] Explicit valence for atom # 12 N, 4, is greater than permitted\n", "[15:56:13] Explicit valence for atom # 5 N, 4, is greater than permitted\n", "[15:56:13] Explicit valence for atom # 5 N, 4, is greater than permitted\n", "[15:56:13] Explicit valence for atom # 5 N, 4, is greater than permitted\n", "[15:56:13] Explicit valence for atom # 5 N, 4, is greater than permitted\n", "[15:56:13] Explicit valence for atom # 5 N, 4, is greater than permitted\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] Explicit valence for atom # 5 N, 4, is greater than permitted\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:13] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:14] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:14] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:14] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:14] WARNING: not removing hydrogen atom without neighbors\n", "[15:56:14] WARNING: not removing hydrogen atom without neighbors\n", "/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["bbbp :: 66.72 +- 5.5\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n", "[15:57:31] WARNING: not removing hydrogen atom without neighbors\n", "/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["tox21 :: 80.11 +- 1.8\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n", "[16:00:23] Explicit valence for atom # 0 F, 2, is greater than permitted\n", "[16:00:23] Explicit valence for atom # 2 Cl, 2, is greater than permitted\n", "[16:00:23] Explicit valence for atom # 0 Cl, 2, is greater than permitted\n", "[16:00:23] WARNING: not removing hydrogen atom without neighbors\n", "[16:00:23] Explicit valence for atom # 3 Si, 8, is greater than permitted\n", "[16:00:23] Explicit valence for atom # 3 Si, 8, is greater than permitted\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:24] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:24] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:25] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:25] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:25] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:25] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:25] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:25] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:25] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:25] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:25] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:25] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "[16:00:25] SMILES Parse Error: syntax error while parsing: FAIL\n", "[16:00:25] SMILES Parse Error: Failed parsing SMILES 'FAIL' for input: 'FAIL'\n", "/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["toxcast :: 88.56 +- 0.9\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n", "[16:03:30] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:30] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:30] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:30] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:30] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:30] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:30] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:30] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:31] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:31] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:31] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:31] WARNING: not removing hydrogen atom without neighbors\n", "[16:03:31] WARNING: not removing hydrogen atom without neighbors\n", "/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["sider :: 80.80 +- 4.5\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n", "[16:04:12] Explicit valence for atom # 0 N, 5, is greater than permitted\n", "[16:04:12] Can't kekulize mol.  Unkekulized atoms: 9\n", "[16:04:12] Explicit valence for atom # 10 N, 4, is greater than permitted\n", "[16:04:12] Explicit valence for atom # 10 N, 4, is greater than permitted\n", "[16:04:12] Can't kekulize mol.  Unkekulized atoms: 4\n", "[16:04:12] Can't kekulize mol.  Unkekulized atoms: 4\n", "/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["clintox :: 70.71 +- 1.9\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n", "/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["muv :: 74.33 +- 0.8\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n", "[16:36:58] WARNING: not removing hydrogen atom without neighbors\n", "[16:36:58] WARNING: not removing hydrogen atom without neighbors\n", "/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["hiv :: 77.02 +- 0.7\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n", "/gpfs/gibbs/project/gerstein/xt86/conda_envs/new-momu-train/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n", "  warnings.warn(msg)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["bace :: 70.55 +- 4.2\n"]}], "source": ["\n", "import statistics\n", "from sklearn.multioutput import MultiOutputClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from itertools import compress\n", "import numpy as np\n", "from torch_geometric.data import InMemoryDataset, Data\n", "from rdkit.Chem.Scaffolds import MurckoScaffold\n", "from sklearn.metrics import roc_auc_score\n", "\n", "\n", "class EmbeddingsDataset(InMemoryDataset):\n", "    def __init__(self, root, transform=None, pre_transform=None):\n", "        super(EmbeddingsDataset, self).__init__(root, transform, pre_transform)\n", "        self.data, self.slices = torch.load(self.processed_paths[0])\n", "\n", "    @property\n", "    def raw_file_names(self):\n", "        return ['molm.pt', 'molm_labels.pt']\n", "\n", "    @property\n", "    def processed_file_names(self):\n", "        return ['data.pt']\n", "\n", "    def download(self):\n", "        pass\n", "\n", "    def process(self):\n", "        data_list = []\n", "\n", "        embeddings = torch.load(f'{self.raw_dir}/molm.pt')\n", "        labels = torch.load(f'{self.raw_dir}/molm_labels.pt')\n", "        labels = labels.values\n", "\n", "        for i, (emb, label) in enumerate(zip(embeddings, labels)):\n", "            emb = emb.squeeze()\n", "            if labels.shape == (1,2):\n", "                y = torch.tensor(labels[i, :])\n", "            else:\n", "                y = torch.tensor([labels[i]])\n", "\n", "            data = Data(x=emb.to('cpu'), y=y)\n", "            data_list.append(data)\n", "\n", "        data, slices = self.collate(data_list)\n", "        torch.save((data, slices), self.processed_paths[0])\n", "\n", "    def len(self):\n", "        return len(self.data.y)\n", "\n", "    def get(self, idx):\n", "        data = Data()\n", "    \n", "        for key in self.data.keys:\n", "            item, slices = self.data[key], self.slices[key]\n", "            start, stop = slices[idx].item(), slices[idx + 1].item()\n", "            data[key] = item[start:stop]\n", "    \n", "        return data\n", "    \n", "    \n", "def scaffold_split(dataset, smiles_list, task_idx=None, null_value=0,\n", "                   frac_train=0.8, frac_valid=0.1, frac_test=0.1,\n", "                   return_smiles=False):\n", "    \"\"\"\n", "    Adapted from https://github.com/deepchem/deepchem/blob/master/deepchem/splits/splitters.py\n", "    Split dataset by Bemis-Murcko scaffolds\n", "    This function can also ignore examples containing null values for a\n", "    selected task when splitting. Deterministic split\n", "    :param dataset: pytorch geometric dataset obj\n", "    :param smiles_list: list of smiles corresponding to the dataset obj\n", "    :param task_idx: column idx of the data.y tensor. Will filter out\n", "    examples with null value in specified task column of the data.y tensor\n", "    prior to splitting. If None, then no filtering\n", "    :param null_value: float that specifies null value in data.y to filter if\n", "    task_idx is provided\n", "    :param frac_train:\n", "    :param frac_valid:\n", "    :param frac_test:\n", "    :param return_smiles:\n", "    :return: train, valid, test slices of the input dataset obj. If\n", "    return_smiles = True, also returns ([train_smiles_list],\n", "    [valid_smiles_list], [test_smiles_list])\n", "    \"\"\"\n", "    np.testing.assert_almost_equal(frac_train + frac_valid + frac_test, 1.0)\n", "\n", "    if task_idx != None:\n", "        # filter based on null values in task_idx\n", "        # get task array\n", "        y_task = np.array([data.y[task_idx].item() for data in dataset])\n", "        # boolean array that correspond to non null values\n", "        non_null = y_task != null_value\n", "        smiles_list = list(compress(enumerate(smiles_list), non_null))\n", "    else:\n", "        non_null = np.ones(len(dataset)) == 1\n", "        smiles_list = list(compress(enumerate(smiles_list), non_null))\n", "\n", "    # create dict of the form {scaffold_i: [idx1, idx....]}\n", "    all_scaffolds = {}\n", "    for i, smiles in smiles_list:\n", "        scaffold = generate_scaffold(smiles, include_chirality=True)\n", "        if scaffold is None:\n", "            continue\n", "        if scaffold not in all_scaffolds:\n", "            all_scaffolds[scaffold] = [i]\n", "        else:\n", "            all_scaffolds[scaffold].append(i)\n", "\n", "    # sort from largest to smallest sets\n", "    all_scaffolds = {key: sorted(value) for key, value in all_scaffolds.items()}\n", "    all_scaffold_sets = [\n", "        scaffold_set for (scaffold, scaffold_set) in sorted(\n", "            all_scaffolds.items(), key=lambda x: (len(x[1]), x[1][0]), reverse=True)\n", "    ]\n", "\n", "    # get train, valid test indices\n", "    train_cutoff = frac_train * len(smiles_list)\n", "    valid_cutoff = (frac_train + frac_valid) * len(smiles_list)\n", "    train_idx, valid_idx, test_idx = [], [], []\n", "    for scaffold_set in all_scaffold_sets:\n", "        if len(train_idx) + len(scaffold_set) > train_cutoff:\n", "            if len(train_idx) + len(valid_idx) + len(scaffold_set) > valid_cutoff:\n", "                test_idx.extend(scaffold_set)\n", "            else:\n", "                valid_idx.extend(scaffold_set)\n", "        else:\n", "            train_idx.extend(scaffold_set)\n", "\n", "    assert len(set(train_idx).intersection(set(valid_idx))) == 0\n", "    assert len(set(test_idx).intersection(set(valid_idx))) == 0\n", "\n", "    train_dataset = dataset[torch.tensor(train_idx)]\n", "    valid_dataset = dataset[torch.tensor(valid_idx)]\n", "    test_dataset = dataset[torch.tensor(test_idx)]\n", "\n", "    if not return_smiles:\n", "        return train_dataset, valid_dataset, test_dataset\n", "    else:\n", "        train_smiles = [smiles_list[i][1] for i in train_idx]\n", "        valid_smiles = [smiles_list[i][1] for i in valid_idx]\n", "        test_smiles = [smiles_list[i][1] for i in test_idx]\n", "        return train_dataset, valid_dataset, test_dataset, (train_smiles,\n", "                                                            valid_smiles,\n", "                                                            test_smiles)\n", "    \n", "def generate_scaffold(smiles, include_chirality=False):\n", "    \"\"\"\n", "    Obtain Bemis-Murcko scaffold from smiles\n", "    :param smiles:\n", "    :param include_chirality:\n", "    :return: smiles of scaffold\n", "    \"\"\"\n", "    try:\n", "        scaffold = MurckoScaffold.MurckoScaffoldSmiles(\n", "        smiles=smiles, includeChirality=include_chirality)\n", "    except:\n", "        # Invalid molecule, just use a random one\n", "        scaffold = MurckoScaffold.MurckoScaffoldSmiles(\n", "        smiles='CCCC', includeChirality=include_chirality)\n", "    return scaffold\n", "    \n", "\n", "for dataset, (dataset_csv, load_dataset_func) in datasets.items():\n", "    cdataset = EmbeddingsDataset(root=f'{dataset_base_path}/hiv/')\n", "    csv_path = f'{dataset_base_path}/{dataset}/raw/{dataset_csv}'\n", "    input_df = pd.read_csv(csv_path, sep=',')\n", "    smiles_list, _ = load_dataset_func(input_df)\n", "    smiles_list = list(smiles_list)\n", "    train_dataset, valid_dataset, test_dataset = scaffold_split(cdataset, smiles_list, null_value=0, frac_train=0.8,frac_valid=0.1, frac_test=0.1)\n", "    \n", "    def extract_features_labels(dataset):\n", "        X = []\n", "        Y = []\n", "        for data in dataset:\n", "            X.append(data.x.numpy())\n", "            Y.append((data.y.numpy() + 1) // 2)\n", "        return np.array(X), np.array(Y)\n", "    \n", "    X_train, Y_train = extract_features_labels(train_dataset)\n", "    X_test, Y_test = extract_features_labels(test_dataset)\n", "    # Found after grid search on validation set\n", "    hyperparams = {\n", "        'bbbp': (100, 20),\n", "        'tox21': (50, 20),\n", "        'toxcast': (100, 9),\n", "        'sider': (150, 9),\n", "        'clintox': (50, 20),\n", "        'muv': (100, 20),\n", "        'hiv': (100, 9),\n", "        'bace': (100, 20)\n", "    }\n", "    n_estimators, max_depth = hyperparams[dataset]\n", "    scores = []\n", "    for _ in range(15):\n", "        forest = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n", "        multi_output_rf = MultiOutputClassifier(forest, n_jobs=-1)\n", "        multi_output_rf.fit(X_train, Y_train)\n", "        Y_pred = multi_output_rf.predict(X_test)\n", "        # Calculate the accuracy\n", "        Y_scores = multi_output_rf.predict_proba(X_test)\n", "    \n", "        # Convert Y_scores to the correct format\n", "        Y_scores_formatted = np.array([Y_scores[i][:, 1] for i in range(len(Y_scores))]).T\n", "        \n", "        roc_list = []\n", "        for i in range(Y_test.shape[1]):\n", "            # Check that there is at least one positive and one negative example\n", "            if np.sum(Y_test[:, i] == 1) > 0 and np.sum(Y_test[:, i] == 0) > 0:\n", "                # Calculate ROC AUC score for the i-th label\n", "                roc_list.append(roc_auc_score(Y_test[:, i], Y_scores_formatted[:, i]))\n", "        \n", "        # Handle case where some labels may not have both positive and negative examples\n", "        if len(roc_list) < Y_test.shape[1]:\n", "            print(\"Some target is missing!\")\n", "            print(\"Missing ratio: %f\" % (1 - float(len(roc_list)) / Y_test.shape[1]))\n", "    \n", "        # Calculate the average ROC AUC score across all labels\n", "        average_roc_auc = sum(roc_list) / len(roc_list)\n", "        scores.append(average_roc_auc)\n", "    avg_score = sum(scores) / 15\n", "    stddev = statistics.stdev(scores) \n", "    print(f\"{dataset} :: {avg_score * 100:.2f} +- {stddev * 100:.1f}\")"], "metadata": {"collapsed": false, "ExecuteTime": {"end_time": "2024-03-15T20:53:54.870042Z", "start_time": "2024-03-15T19:56:12.839480Z"}}, "id": "243e5dd832a6eefc", "execution_count": 5}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.6"}}, "nbformat": 4, "nbformat_minor": 5}